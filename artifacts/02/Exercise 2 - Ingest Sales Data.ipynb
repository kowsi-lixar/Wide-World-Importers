{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// Set the path to read the WWI Sales files\n",
        "import org.apache.spark.sql.SparkSession\n",
        "\n",
        "// Set the path to the ADLS Gen2 account\n",
        "val adlsPath = \"abfss://wwi@<primary_storage>.dfs.core.windows.net\"\n",
        "\n",
        "// Set to the unique ID (e.g., A03) you were assigned for this workshop.\n",
        "val uniqueId = \"\"\n",
        "\n",
        "// Validate a uniqueId was entered\n",
        "if (uniqueId ==  \"\") {\n",
        "    throw new Exception(\"You must enter the unique identifier you were assigned for this workshop into the uniqueId variable before proceeding.\")\n",
        "}"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// Validate a uniqueId was entered\n",
        "if (uniqueId ==  \"\") {\n",
        "    throw new Exception(\"You must enter the unique identifier you were assigned for this workshop into the uniqueId variable before proceeding.\")\n",
        "}\n",
        "\n",
        "// Read the sales into a dataframe\n",
        "val sales = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"sep\", \"|\").load(s\"$adlsPath/factsale-csv/2012/Q4\")\n",
        "sales.show(5)\n",
        "sales.printSchema()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// Import libraries for the SQL Analytics connector\n",
        "import com.microsoft.spark.sqlanalytics.utils.Constants\n",
        "import org.apache.spark.sql.SqlAnalyticsConnector._\n",
        "import org.apache.spark.sql.SaveMode\n",
        "\n",
        "// Set target table name\n",
        "var tableName = s\"SQLPool01.wwi_staging.Sale_$uniqueId\"\n",
        "\n",
        "if (tableName ==  \"SQLPool01.wwi_staging.Sale_\") {\n",
        "    throw new Exception(\"You must set the uniqueId variable before proceeding to ensure your table name is unique.\")\n",
        "}\n",
        "\n",
        "// Write the retrieved sales data into a staging table in Azure Synapse Analytics.\n",
        "sales.limit(10000).write.mode(SaveMode.Append).sqlanalytics(tableName, Constants.INTERNAL)"
      ],
      "attachments": {}
    }
  ]
}